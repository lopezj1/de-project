{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile, is_zipfile\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "from prefect import flow, task\n",
    "from prefect_gcp.cloud_storage import GcsBucket\n",
    "from google.cloud import storage\n",
    "import gcsfs\n",
    "import json\n",
    "import gzip\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @task()\n",
    "# def read_gcs_bucket(connection, bucket_name: str) -> list:\n",
    "#     \"\"\"Get list of zip folders in GCS bucket\"\"\"\n",
    "#     lsblob = connection.ls(f'{bucket_name}/zip')\n",
    "#     # lsblob = [l.rsplit('/', 1)[-1] for l in lsblob] #only return the filename from the blob\n",
    "#     print(lsblob)\n",
    "    \n",
    "#     return lsblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @task()\n",
    "# def unzip_blob(connection, source_path: str\n",
    "#                 # , destination_path: str\n",
    "#                 # , bucket\n",
    "#                 ) -> list:\n",
    "#     \"\"\"Unzip folder\"\"\"\n",
    "\n",
    "#     with connection.open(source_path, 'rb') as f:\n",
    "#         print(f.readline())\n",
    "        \n",
    "        \n",
    "#     #     g = gzip.GzipFile(fileobj=f)  # Decompress data with gzip\n",
    "#     #     df = pd.read_csv(g)           # Read CSV file with Pandas\n",
    "\n",
    "#     # print(df.head())\n",
    "\n",
    "#     # blob = bucket.blob(source_path)\n",
    "#     # tmp_dir = '../tmp'\n",
    "#     # Path(tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # with open('../tmp/archive.zip', 'wb') as file_obj:\n",
    "#     #     blob.download_to_file(file_obj)\n",
    "\n",
    "#     # zip_archive = ZipFile('../tmp/archive.zip', 'r')\n",
    "    \n",
    "#     # destination_blob = bucket.blob(destination_path)\n",
    "#     # zip_archive.extractall(destination_path)\n",
    "    \n",
    "#     # return zip_archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task()\n",
    "def convert_to_parquet():\n",
    "    \"\"\"Upload local parquet file to GCS\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @flow(log_prints=True)\n",
    "# def process_gcs_blob() -> None:\n",
    "#     \"\"\"Process blob in gcs bucket\"\"\"\n",
    "#     file =  open(\"../creds.json\", 'r') #json file for key\n",
    "#     token = json.load(file) #convert json file to python dictionary\n",
    "#     bucket_name = 'de_project_bucket'\n",
    "#     fs = gcsfs.GCSFileSystem(project=' DTC DE Course'\n",
    "#                             , token=token\n",
    "#                             )\n",
    "\n",
    "#     lsblob = read_gcs_bucket(fs, bucket_name)\n",
    "#     source = lsblob[0]\n",
    "#     df = unzip_blob(fs, source)\n",
    "#     # lsfiles = unzip_blob(source, destination, bucket)\n",
    "\n",
    "#     # storage_client = storage.Client.from_service_account_json(\"../creds.json\")\n",
    "#     # bucket_name = 'de_project_bucket' #parameterize this\n",
    "#     # bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "#     # destination = 'unzip/'\n",
    "#     # lsblob = read_gcs_bucket(bucket)\n",
    "\n",
    "#     # source = lsblob[0]\n",
    "#     # lsfiles = unzip_blob(source, destination, bucket)\n",
    "\n",
    "#     # for blob in lsblob:\n",
    "#     #     lsfiles = unzip_blob(blob, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task()\n",
    "def read_gcs_bucket(bucket) -> list:\n",
    "    \"\"\"Get list of zip folders in GCS bucket\"\"\"\n",
    "    lsblob = list(bucket.list_blobs(prefix=\"zip\"))\n",
    "    lsblob = [l.name for l in lsblob] #only return the filename from the blob\n",
    "    print(lsblob)\n",
    "    \n",
    "    return lsblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @task()\n",
    "def unzip_blob(source_path: str, destination_path: str, bucket) -> list:\n",
    "    \"\"\"Unzip folder\"\"\"\n",
    "    blob = bucket.blob(source_path)\n",
    "\n",
    "    zipbytes = io.BytesIO(blob.download_as_string())\n",
    "\n",
    "    if is_zipfile(zipbytes):\n",
    "        with ZipFile(zipbytes, 'r') as myzip:\n",
    "            for contentfilename in myzip.namelist():\n",
    "                contentfile = myzip.read(contentfilename)\n",
    "                print(contentfile)\n",
    "\n",
    "\n",
    "    # tmp_dir = '../tmp'\n",
    "    # Path(tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # with open('../tmp/archive.zip', 'wb') as file_obj:\n",
    "    #     blob.download_to_file(file_obj)\n",
    "\n",
    "    # zip_archive = ZipFile('../tmp/archive.zip', 'r')\n",
    "    \n",
    "    # destination_blob = bucket.blob(destination_path)\n",
    "    # zip_archive.extractall(destination_path)\n",
    "    \n",
    "    # return zip_archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @flow(log_prints=True)\n",
    "def process_gcs_blob() -> None:\n",
    "    \"\"\"Process blob in gcs bucket\"\"\"\n",
    "    storage_client = storage.Client.from_service_account_json(\"../creds.json\")\n",
    "    bucket_name = 'de_project_bucket' #parameterize this\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    destination = 'unzip/'\n",
    "    lsblob = read_gcs_bucket(bucket)\n",
    "\n",
    "    source = lsblob[0]\n",
    "    lsfiles = unzip_blob(source, destination, bucket)\n",
    "\n",
    "    # for blob in lsblob:\n",
    "    #     lsfiles = unzip_blob(blob, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zip/ps_1981_1989_csv.zip', 'zip/ps_1990_1994_csv.zip', 'zip/ps_1995_1999_csv.zip', 'zip/ps_2000_2004_csv.zip', 'zip/ps_2005_2009_csv.zip', 'zip/ps_2010_2014_csv.zip', 'zip/ps_2015_2016_csv.zip', 'zip/ps_2017_csv.zip', 'zip/ps_2018_csv.zip', 'zip/ps_2019_csv.zip', 'zip/ps_2020_csv.zip', 'zip/ps_2021_csv.zip']\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "process_gcs_blob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "254721729ad41773dee351bfff8b617bf657a0a6ef8ca8070296dad6f2976db6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
